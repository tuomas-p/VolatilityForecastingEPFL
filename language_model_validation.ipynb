{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language model validation with testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tuomasp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/tuomasp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/tuomasp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/tuomasp/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "\n",
    "import emoji\n",
    "import datetime\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "\n",
    "# Create a list of stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Create a function to clean the tweets\n",
    "def clean_tweets(tweet):\n",
    "    # Remove usernames\n",
    "    tweet = re.sub(r'@[A-Za-z0-9_]+', '', tweet)\n",
    "    # Remove emojis \n",
    "    tweet = emoji.demojize(tweet)\n",
    "    # Tokenize the tweet by words\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    # Remove stopwords\n",
    "    tweet_no_stopwords = [word.lower() for word in tweet_tokens if word.lower() not in stop_words]\n",
    "    # Remove punctuation\n",
    "    tweets_no_punc = [''.join([char for char in word if char not in punctuations]) for word in tweet_no_stopwords]\n",
    "    # Remove empty strings\n",
    "    tweets_no_punc = [word for word in tweets_no_punc if word != '']\n",
    "    # Remove links\n",
    "    tweets_no_punc = [word for word in tweets_no_punc if not 'http' in word]\n",
    "    # Remove words with one character\n",
    "    tweets_no_punc = [word for word in tweets_no_punc if len(word) > 1]\n",
    "\n",
    "    return tweets_no_punc\n",
    "\n",
    "# Create a function to lemmatize the tweets\n",
    "def lemmatize_tweets(tweet):\n",
    "\n",
    "    # Initialize the WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Lemmatize the tweet\n",
    "    tweet_lemmatized = [lemmatizer.lemmatize(word) for word in tweet]\n",
    "    # Return the list of lemmatized words\n",
    "    return tweet_lemmatized\n",
    "\n",
    "# Create a function to get the polarity of the tweets\n",
    "def get_polarity(tweet):\n",
    "    # Create a TextBlob object\n",
    "    analysis = TextBlob(tweet)\n",
    "    # Return the polarity\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Create a function to get the subjectivity of the tweets\n",
    "def get_subjectivity(tweet):\n",
    "    # Create a TextBlob object\n",
    "    analysis = TextBlob(tweet)\n",
    "    # Return the subjectivity\n",
    "    return analysis.sentiment.subjectivity\n",
    "\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_decider(compound):\n",
    "    polarity = \"neutral\"\n",
    "\n",
    "    if(compound >= 0.05):\n",
    "        polarity = \"positive\"\n",
    "\n",
    "    elif(compound <= -0.05):\n",
    "        polarity = \"negative\"\n",
    "\n",
    "    return polarity\n",
    "\n",
    "\n",
    "def predict_polarity_vader(text):\n",
    "    output_dict =  vader_analyzer.polarity_scores(text)\n",
    "    return output_dict['compound']\n",
    "\n",
    "def predict_sentiment_vader(text):\n",
    "    output_dict =  vader_analyzer.polarity_scores(text)\n",
    "    return sentiment_decider(output_dict['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tb_polarity</th>\n",
       "      <th>tb_sentiment</th>\n",
       "      <th>vader_polarity</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>tb_valid_sentiment</th>\n",
       "      <th>vader_valid_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>My cat only chews  cords. Such an #AppleSnob.</td>\n",
       "      <td>[cat, chew, cord, applesnob]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>negative</td>\n",
       "      <td>WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...</td>\n",
       "      <td>[wtf, battery, 31, one, second, ago, 29, wtf]</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.8769</td>\n",
       "      <td>negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT : Bought my  at the  store..pretty good log...</td>\n",
       "      <td>[rt, bought, store, pretty, good, logo, match,...</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>negative</td>\n",
       "      <td>Contact sync between Yosemite and iOS8 is ser...</td>\n",
       "      <td>[contact, sync, yosemite, ios8, seriously, scr...</td>\n",
       "      <td>-0.127778</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.3415</td>\n",
       "      <td>negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why #AAPL Stock Had a Mini-Flash Crash Today: ...</td>\n",
       "      <td>[aapl, stock, miniflash, crash, today, money, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.4019</td>\n",
       "      <td>negative</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "2    neutral      My cat only chews  cords. Such an #AppleSnob.   \n",
       "10  negative  WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...   \n",
       "13  positive  RT : Bought my  at the  store..pretty good log...   \n",
       "14  negative   Contact sync between Yosemite and iOS8 is ser...   \n",
       "19   neutral  Why #AAPL Stock Had a Mini-Flash Crash Today: ...   \n",
       "\n",
       "                                           text_clean  tb_polarity  \\\n",
       "2                        [cat, chew, cord, applesnob]     0.000000   \n",
       "10      [wtf, battery, 31, one, second, ago, 29, wtf]    -0.333333   \n",
       "13  [rt, bought, store, pretty, good, logo, match,...     0.475000   \n",
       "14  [contact, sync, yosemite, ios8, seriously, scr...    -0.127778   \n",
       "19  [aapl, stock, miniflash, crash, today, money, ...     0.000000   \n",
       "\n",
       "   tb_sentiment  vader_polarity vader_sentiment  tb_valid_sentiment  \\\n",
       "2       neutral          0.0000         neutral                True   \n",
       "10     negative         -0.8769        negative                True   \n",
       "13     positive          0.4926        positive                True   \n",
       "14     negative         -0.3415        negative                True   \n",
       "19      neutral         -0.4019        negative                True   \n",
       "\n",
       "    vader_valid_sentiment  \n",
       "2                    True  \n",
       "10                   True  \n",
       "13                   True  \n",
       "14                   True  \n",
       "19                  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation dataset preparation\n",
    "sentiment_dict = {'1': 'negative', '3': 'neutral', '5': 'positive'}\n",
    "df_validation_apple = pd.read_csv('Apple-Twitter-Sentiment-DFE.csv', encoding = 'unicode_escape')\n",
    "df_validation_apple = df_validation_apple.loc[df_validation_apple['sentiment:confidence'] == 1][['sentiment', 'text']]\n",
    "df_validation_apple = df_validation_apple[df_validation_apple['sentiment'].isin(sentiment_dict.keys())]\n",
    "df_validation_apple['sentiment'] = df_validation_apple['sentiment'].apply(lambda x: sentiment_dict[x])\n",
    "\n",
    "# Clean the tweets\n",
    "df_validation_apple['text_clean'] = df_validation_apple['text'].apply(lambda x: str(clean_tweets(x)))\n",
    "df_validation_apple['text'] = df_validation_apple['text'].apply(lambda x: re.sub(r'@[A-Za-z0-9_]+', '', x))\n",
    "\n",
    "# Lemmatize them\n",
    "df_validation_apple['text_clean'] = df_validation_apple['text_clean'].apply(lambda x: lemmatize_tweets(eval(x)))\n",
    "\n",
    "# TextBlob polarity evaluation\n",
    "df_validation_apple['tb_polarity'] = df_validation_apple['text_clean'].apply(lambda x: get_polarity(str(x)))\n",
    "df_validation_apple['tb_sentiment'] = df_validation_apple['tb_polarity'].apply(lambda x: sentiment_decider(x))\n",
    "\n",
    "# VADER polarity evaluation\n",
    "df_validation_apple['vader_polarity'] = df_validation_apple['text'].apply(lambda x: predict_polarity_vader(x))\n",
    "df_validation_apple['vader_sentiment'] = df_validation_apple['text'].apply(lambda x: predict_sentiment_vader(x))\n",
    "\n",
    "df_validation_apple['tb_valid_sentiment'] = df_validation_apple['tb_sentiment'] == df_validation_apple['sentiment']\n",
    "df_validation_apple['vader_valid_sentiment'] = df_validation_apple['vader_sentiment'] == df_validation_apple['sentiment']\n",
    "\n",
    "# Print the first 5 rows of the cleaned tweets\n",
    "df_validation_apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the total amount of right predictions using polarity thresholds of -0.05 and 0.05, VADER predicted correctly 1176 (62.35%) and TextBlob 1113 (59.01%) out of 1886 total samples.\n",
      "\n",
      "For the true positive labels, VADER predicted 137 as positive, 18 as neutral and 4 as negative.\n",
      "For the true neutral labels, VADER predicted 285 as positive, 602 as neutral and 137 as negative.\n",
      "For the true negative labels, VADER predicted 137 as positive, 129 as neutral and 437 as negative.\n",
      "\n",
      "For the true positive labels, TextBlob predicted 117 as positive, 39 as neutral and 3 as negative.\n",
      "For the true neutral labels, TextBlob predicted 262 as positive, 682 as neutral and 80 as negative.\n",
      "For the true negative labels, TextBlob predicted 134 as positive, 255 as neutral and 314 as negative.\n"
     ]
    }
   ],
   "source": [
    "# statistics over whole dataset\n",
    "vader_right_sentiments = len(df_validation_apple[df_validation_apple['vader_valid_sentiment'] == 1])\n",
    "tb_right_sentiments = len(df_validation_apple[df_validation_apple['tb_valid_sentiment'] == 1])\n",
    "total_sentiments = len(df_validation_apple)\n",
    "vader_perc = vader_right_sentiments / total_sentiments * 100\n",
    "tb_perc = tb_right_sentiments / total_sentiments * 100\n",
    "\n",
    "# statistics for confusion matrix (notation: model_TrueLabel_PredictedLabel)\n",
    "# VADER\n",
    "df_apple_pos = df_validation_apple[df_validation_apple['sentiment'] == 'positive']\n",
    "vader_Pos_Pos = len(df_apple_pos[df_apple_pos['vader_sentiment'] == 'positive'])\n",
    "vader_Pos_Neu = len(df_apple_pos[df_apple_pos['vader_sentiment'] == 'neutral'])\n",
    "vader_Pos_Neg = len(df_apple_pos[df_apple_pos['vader_sentiment'] == 'negative'])\n",
    "\n",
    "df_apple_neu = df_validation_apple[df_validation_apple['sentiment'] == 'neutral']\n",
    "vader_Neu_Pos = len(df_apple_neu[df_apple_neu['vader_sentiment'] == 'positive'])\n",
    "vader_Neu_Neu = len(df_apple_neu[df_apple_neu['vader_sentiment'] == 'neutral'])\n",
    "vader_Neu_Neg = len(df_apple_neu[df_apple_neu['vader_sentiment'] == 'negative'])\n",
    "\n",
    "df_apple_neg = df_validation_apple[df_validation_apple['sentiment'] == 'negative']\n",
    "vader_Neg_Pos = len(df_apple_neg[df_apple_neg['vader_sentiment'] == 'positive'])\n",
    "vader_Neg_Neu = len(df_apple_neg[df_apple_neg['vader_sentiment'] == 'neutral'])\n",
    "vader_Neg_Neg = len(df_apple_neg[df_apple_neg['vader_sentiment'] == 'negative'])\n",
    "\n",
    "# TextBlob\n",
    "tb_Pos_Pos = len(df_apple_pos[df_apple_pos['tb_sentiment'] == 'positive'])\n",
    "tb_Pos_Neu = len(df_apple_pos[df_apple_pos['tb_sentiment'] == 'neutral'])\n",
    "tb_Pos_Neg = len(df_apple_pos[df_apple_pos['tb_sentiment'] == 'negative'])\n",
    "\n",
    "tb_Neu_Pos = len(df_apple_neu[df_apple_neu['tb_sentiment'] == 'positive'])\n",
    "tb_Neu_Neu = len(df_apple_neu[df_apple_neu['tb_sentiment'] == 'neutral'])\n",
    "tb_Neu_Neg = len(df_apple_neu[df_apple_neu['tb_sentiment'] == 'negative'])\n",
    "\n",
    "tb_Neg_Pos = len(df_apple_neg[df_apple_neg['tb_sentiment'] == 'positive'])\n",
    "tb_Neg_Neu = len(df_apple_neg[df_apple_neg['tb_sentiment'] == 'neutral'])\n",
    "tb_Neg_Neg = len(df_apple_neg[df_apple_neg['tb_sentiment'] == 'negative'])\n",
    "\n",
    "print(\"For the total amount of right predictions using polarity thresholds of -0.05 and 0.05, VADER predicted correctly {:d} ({:.2f}%) and TextBlob {:d} ({:.2f}%) out of {:d} total samples.\\n\".format(vader_right_sentiments, vader_perc, tb_right_sentiments, tb_perc, total_sentiments))\n",
    "\n",
    "print(\"For the true positive labels, VADER predicted {:d} as positive, {:d} as neutral and {:d} as negative.\".format(vader_Pos_Pos, vader_Pos_Neu, vader_Pos_Neg))\n",
    "print(\"For the true neutral labels, VADER predicted {:d} as positive, {:d} as neutral and {:d} as negative.\".format(vader_Neu_Pos, vader_Neu_Neu, vader_Neu_Neg))\n",
    "print(\"For the true negative labels, VADER predicted {:d} as positive, {:d} as neutral and {:d} as negative.\\n\".format(vader_Neg_Pos, vader_Neg_Neu, vader_Neg_Neg))\n",
    "\n",
    "print(\"For the true positive labels, TextBlob predicted {:d} as positive, {:d} as neutral and {:d} as negative.\".format(tb_Pos_Pos, tb_Pos_Neu, tb_Pos_Neg))\n",
    "print(\"For the true neutral labels, TextBlob predicted {:d} as positive, {:d} as neutral and {:d} as negative.\".format(tb_Neu_Pos, tb_Neu_Neu, tb_Neu_Neg))\n",
    "print(\"For the true negative labels, TextBlob predicted {:d} as positive, {:d} as neutral and {:d} as negative.\".format(tb_Neg_Pos, tb_Neg_Neu, tb_Neg_Neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42e05fb1f30d9962acb834c3f570df1016b8bdf405ec089adf1b2c5f0e3bdd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
